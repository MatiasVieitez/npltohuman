{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# if you are using MySQL\n",
    "mysql_uri = 'mysql+mysqlconnector://root:root@localhost:3306/chinook'\n",
    "\n",
    "db = SQLDatabase.from_uri(mysql_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema(_):\n",
    "    return db.get_table_info()\n",
    "\n",
    "\n",
    "get_schema(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(schema=get_schema)\n",
    "    | prompt\n",
    "    | llm.bind(stop=[\"\\nSQLResult:\"])\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(*) AS total_albums\\nFROM album;'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_question = 'how many albums are there in the database?'\n",
    "sql_chain.invoke({\"question\": user_question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "prompt_response = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query):\n",
    "    return db.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_chain).assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda vars: run_query(vars[\"query\"]),\n",
    "    )\n",
    "    | prompt_response\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 347 albums in the database.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_question = 'how many albums are there in the database?'\n",
    "full_chain.invoke({\"question\": user_question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PromptTemplateChain' from 'langchain.chains' (c:\\Users\\matia\\miniconda3\\envs\\chat-bot\\lib\\site-packages\\langchain\\chains\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\matia\\OneDrive\\Documentos\\Desarrollo\\Chatbot\\main.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/matia/OneDrive/Documentos/Desarrollo/Chatbot/main.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m \u001b[39mimport\u001b[39;00m LLMChain, PromptTemplateChain\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/matia/OneDrive/Documentos/Desarrollo/Chatbot/main.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprompts\u001b[39;00m \u001b[39mimport\u001b[39;00m ChatPromptTemplate\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/matia/OneDrive/Documentos/Desarrollo/Chatbot/main.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moutput_parsers\u001b[39;00m \u001b[39mimport\u001b[39;00m StrOutputParser\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'PromptTemplateChain' from 'langchain.chains' (c:\\Users\\matia\\miniconda3\\envs\\chat-bot\\lib\\site-packages\\langchain\\chains\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain, PromptTemplateChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import StrOutputParser\n",
    "from langchain.runnables import RunnablePassthrough\n",
    "\n",
    "# Definir el template de prompt\n",
    "template = \"\"\"Based on the table schema below, question, sql query, and sql response, write a natural language response:\n",
    "{schema}\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Response: {response}\"\"\"\n",
    "\n",
    "prompt_response = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def run_query(query):\n",
    "    return db.run(query)\n",
    "\n",
    "# Crear una función que genere la respuesta completa incluyendo la query y la explicación\n",
    "def generate_full_response(vars):\n",
    "    schema = get_schema()\n",
    "    query = sql_chain(vars[\"question\"])\n",
    "    response = run_query(query)\n",
    "    explanation = llm({\"input\": f\"Explain why the following query was generated for the question '{vars['question']}':\\n\\n{query}\"})\n",
    "    return {\n",
    "        \"schema\": schema,\n",
    "        \"question\": vars[\"question\"],\n",
    "        \"query\": query,\n",
    "        \"response\": response,\n",
    "        \"explanation\": explanation\n",
    "    }\n",
    "\n",
    "# Definir el chain completo\n",
    "full_chain = (\n",
    "    RunnablePassthrough\n",
    "    .assign(query=sql_chain)\n",
    "    .assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda vars: run_query(vars[\"query\"]),\n",
    "    )\n",
    "    .map(generate_full_response)\n",
    "    | prompt_response\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "user_question = 'how many albums are there in the database?'\n",
    "result = full_chain.invoke({\"question\": user_question})\n",
    "\n",
    "# Mostrar el resultado final\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
